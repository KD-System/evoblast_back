"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏
–§–æ–Ω–æ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è Vector Store
"""
import asyncio
import base64
import io
import logging
from typing import Dict, Any, List, Tuple, Optional
from fastapi import UploadFile

from app.database import mongodb
from app.services import yandex_service

logger = logging.getLogger(__name__)

ALLOWED_EXTENSIONS = {'txt', 'pdf', 'doc', 'docx', 'md', 'json', 'csv', 'xls', 'xlsx'}
MAX_FILE_SIZE = 30 * 1024 * 1024  # 30 MB
MAX_FILES_PER_UPLOAD = 10


def extract_text_from_file(content: bytes, file_type: str) -> str:
    """–ò–∑–≤–ª–µ—á—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        if file_type in ('txt', 'md', 'json', 'csv'):
            return content.decode('utf-8', errors='ignore')

        # PDF
        if file_type == 'pdf':
            try:
                from PyPDF2 import PdfReader
                reader = PdfReader(io.BytesIO(content))
                text_parts = []
                for page in reader.pages:
                    text_parts.append(page.extract_text() or "")
                return "\n".join(text_parts)
            except Exception as e:
                logger.warning(f"PDF extraction failed: {e}")
                return ""

        # DOCX
        if file_type == 'docx':
            try:
                from docx import Document
                doc = Document(io.BytesIO(content))
                text_parts = [p.text for p in doc.paragraphs]
                return "\n".join(text_parts)
            except Exception as e:
                logger.warning(f"DOCX extraction failed: {e}")
                return ""

        # XLSX
        if file_type == 'xlsx':
            try:
                from openpyxl import load_workbook
                wb = load_workbook(io.BytesIO(content), read_only=True)
                text_parts = []
                for sheet in wb.worksheets:
                    for row in sheet.iter_rows(values_only=True):
                        row_text = " | ".join(str(c) for c in row if c)
                        if row_text:
                            text_parts.append(row_text)
                return "\n".join(text_parts)
            except Exception as e:
                logger.warning(f"XLSX extraction failed: {e}")
                return ""

        # DOC, XLS ‚Äî —Å—Ç–∞—Ä—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã, —Å–ª–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å
        if file_type in ('doc', 'xls'):
            return f"[–§–∞–π–ª —Ñ–æ—Ä–º–∞—Ç–∞ .{file_type} ‚Äî –ø—Ä–µ–≤—å—é –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ]"

        return ""
    except Exception as e:
        logger.error(f"Text extraction error: {e}")
        return ""

# –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
_indexing_status: Dict[str, Any] = {
    "is_indexing": False,
    "message": "idle",
    "files_count": 0
}


def get_indexing_status() -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    return _indexing_status.copy()


def _set_indexing_status(is_indexing: bool, message: str, files_count: int = 0):
    """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    global _indexing_status
    _indexing_status = {
        "is_indexing": is_indexing,
        "message": message,
        "files_count": files_count
    }


def get_file_extension(filename: str) -> str:
    if '.' in filename:
        return filename.rsplit('.', 1)[1].lower()
    return ''


def is_allowed_file(filename: str) -> bool:
    return get_file_extension(filename) in ALLOWED_EXTENSIONS


async def _rebuild_vector_store() -> Optional[str]:
    """
    –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å Vector Store —Å–æ –≤—Å–µ–º–∏ –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏.
    –ï—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç ‚Äî —É–¥–∞–ª—è–µ—Ç Vector Store –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç ID.
    """
    old_vector_store_id = await mongodb.get_current_vector_store_id()

    # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –∞–∫—Ç–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ user_id)
    files = await mongodb.get_all_active_files()

    # –°–æ–±–∏—Ä–∞–µ–º Yandex file IDs
    yandex_file_ids = [f["yandex_file_id"] for f in files if f.get("yandex_file_id")]

    # –ï—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç ‚Äî —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π Vector Store –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º ID
    if not yandex_file_ids:
        logger.warning("‚ö†Ô∏è No files to index, clearing Vector Store")

        if old_vector_store_id:
            await yandex_service.delete_vector_store(old_vector_store_id)

        await mongodb.set_current_vector_store_id("")
        yandex_service.set_vector_store_id("")

        return None

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π Vector Store
    new_vector_store_id = await yandex_service.create_vector_store(yandex_file_ids)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ MongoDB
    await mongodb.set_current_vector_store_id(new_vector_store_id)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
    yandex_service.set_vector_store_id(new_vector_store_id)

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π Vector Store
    if old_vector_store_id and old_vector_store_id != new_vector_store_id:
        await yandex_service.delete_vector_store(old_vector_store_id)

    logger.info(f"‚úÖ Vector Store rebuilt: {new_vector_store_id}")
    return new_vector_store_id


async def rebuild_vector_store_background():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è Vector Store"""
    try:
        files = await mongodb.get_all_active_files()
        files_count = len(files)

        _set_indexing_status(True, "indexing", files_count)
        logger.info(f"üîÑ Starting background indexing for {files_count} files...")

        await _rebuild_vector_store()

        _set_indexing_status(False, "completed", files_count)
        logger.info(f"‚úÖ Background indexing completed for {files_count} files")

    except Exception as e:
        logger.error(f"‚ùå Background indexing failed: {e}")
        _set_indexing_status(False, f"error: {str(e)}", 0)


async def upload_files(
    user_id: str,
    files: List[UploadFile],
    metadata: Dict[str, Any] = None
) -> Tuple[List[Dict[str, Any]], List[str]]:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã –≤ Yandex Cloud.
    Vector Store —Å–æ–∑–¥–∞—ë—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É.
    """
    if len(files) > MAX_FILES_PER_UPLOAD:
        raise ValueError(f"–ú–∞–∫—Å–∏–º—É–º {MAX_FILES_PER_UPLOAD} —Ñ–∞–π–ª–æ–≤ –∑–∞ —Ä–∞–∑")

    uploaded_files = []
    errors = []

    for file in files:
        try:
            if not is_allowed_file(file.filename):
                errors.append(f"{file.filename}: –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø")
                continue

            content = await file.read()
            file_size = len(content)

            if file_size > MAX_FILE_SIZE:
                errors.append(f"{file.filename}: —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. 30MB)")
                continue

            file_type = get_file_extension(file.filename)

            # –ö–æ–¥–∏—Ä—É–µ–º –±–∏–Ω–∞—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ base64 –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ MongoDB
            binary_content_b64 = base64.b64encode(content).decode('ascii')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–µ–≤—å—é (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å PDF, DOCX, XLSX –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏)
            text_content = extract_text_from_file(content, file_type)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Yandex Cloud
            yandex_file_id = await yandex_service.upload_file_to_yandex(content, file.filename)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å—å –≤ MongoDB —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º "uploaded"
            file_record = await mongodb.create_file_record(
                user_id=user_id,
                filename=file.filename,
                file_type=file_type,
                file_size=file_size,
                yandex_file_id=yandex_file_id,
                content=text_content,
                binary_content=binary_content_b64,
                metadata=metadata or {},
                status="uploaded"  # –ï—â—ë –Ω–µ –≤ –∏–Ω–¥–µ–∫—Å–µ
            )

            uploaded_files.append(file_record)
            logger.info(f"‚úÖ File uploaded: {file.filename}")

        except Exception as e:
            logger.error(f"‚ùå Error uploading {file.filename}: {e}")
            errors.append(f"{file.filename}: {str(e)}")

    return uploaded_files, errors


async def upload_files_with_indexing(
    user_id: str,
    files: List[UploadFile],
    metadata: Dict[str, Any] = None
) -> Tuple[List[Dict[str, Any]], List[str]]:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã –ò –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –¥–æ–∂–¥–∞—Ç—å—Å—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
    """
    uploaded_files, errors = await upload_files(user_id, files, metadata)

    if uploaded_files:
        try:
            await _rebuild_vector_store()
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–æ–≤ –Ω–∞ "ready"
            for f in uploaded_files:
                await mongodb.update_file_status(f["file_id"], "ready")
        except Exception as e:
            logger.error(f"‚ùå Failed to rebuild Vector Store: {e}")
            errors.append(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {str(e)}")

    return uploaded_files, errors


async def get_all_files() -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –í–°–ï–• —Ñ–∞–π–ª–æ–≤ (–¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)"""
    files = await mongodb.get_all_active_files()

    for f in files:
        if "_id" in f:
            del f["_id"]
        if "content" in f:
            del f["content"]
        if "binary_content" in f:
            del f["binary_content"]

    return files


async def get_user_files(user_id: str) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    files = await mongodb.get_user_files(user_id)

    for f in files:
        if "_id" in f:
            del f["_id"]
        if "content" in f:
            del f["content"]
        if "binary_content" in f:
            del f["binary_content"]

    return files


async def get_file(file_id: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª –ø–æ ID"""
    file = await mongodb.get_file_by_id(file_id)

    if not file:
        raise ValueError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_id}")

    if "_id" in file:
        del file["_id"]

    return file


async def delete_file(file_id: str) -> bool:
    """–£–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å Vector Store"""
    file = await mongodb.delete_file_record(file_id)

    if not file:
        raise ValueError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_id}")

    if file.get("yandex_file_id"):
        await yandex_service.delete_file_from_yandex(file["yandex_file_id"])

    try:
        await _rebuild_vector_store()
    except Exception as e:
        logger.error(f"‚ùå Failed to rebuild Vector Store: {e}")

    logger.info(f"üóëÔ∏è File deleted: {file_id}")
    return True


async def delete_all_files() -> int:
    """–£–¥–∞–ª–∏—Ç—å –í–°–ï —Ñ–∞–π–ª—ã –∏ –æ—á–∏—Å—Ç–∏—Ç—å Vector Store"""
    files = await mongodb.get_all_active_files()

    # –£–¥–∞–ª—è–µ–º –∏–∑ Yandex Cloud
    for file in files:
        if file.get("yandex_file_id"):
            try:
                await yandex_service.delete_file_from_yandex(file["yandex_file_id"])
            except:
                pass

    # –ü–æ–º–µ—á–∞–µ–º –≤—Å–µ –∫–∞–∫ —É–¥–∞–ª—ë–Ω–Ω—ã–µ –≤ MongoDB
    deleted_count = await mongodb.delete_all_files()

    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º (—É–¥–∞–ª–∏–º) Vector Store
    try:
        await _rebuild_vector_store()
    except Exception as e:
        logger.error(f"‚ùå Failed to rebuild Vector Store: {e}")

    logger.info(f"üóëÔ∏è Deleted all {deleted_count} files")
    return deleted_count


async def get_current_vector_store_id() -> Optional[str]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π Vector Store ID"""
    return await mongodb.get_current_vector_store_id()
